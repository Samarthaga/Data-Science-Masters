{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cab406-1ad5-468f-ad02-49f800e193d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 1:Lasso regression analysis is a shrinkage and variable selection method for linear regression models. The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable\n",
    "## Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights. Thus, the absolute values of weight will be (in general) reduced, and many will tend to be zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be4e49-bb2e-4821-9136-ab65ee1153b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 2 : The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453c158-877a-4fb0-9628-2af9c14b924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 3: A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd66df2-a918-4920-b9fc-45b6f1d1de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 4: A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean.\n",
    "## the more will be the value of lambda in model the more it will be closer to zero and will reach a point where after addition of lambda not bif diff. will ocur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c5d50-e71f-4226-b423-1a909129c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 5: Regularization with a lasso penalty is an advantageous in that it estimates some coefficients in linear regression models to be exactly zero. We propose imposing a weighted lasso penalty on a nonlinear regression model and thereby selecting the number of basis functions effectively\\\n",
    "## As lasso eliminates the least correlated variable which is not very imp and is not creating a big effect in results therefore helps in feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1117e-38cb-4788-a3d9-8595070d1e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 6: Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by introducing a penalty factor. However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square. Ridge regression is also referred to as L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3c0fa-c9c0-4a90-aab6-5835a86ad1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 7: LASSO regression is useful when you have some multicollinearity in your model. Multicollinearity means that the predictors variables, also known as independent variables, aren't so independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2aed5-1482-4cd0-95fe-de1933bbceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 8: The value of lambda will be chosen by cross-validation. The plot shows cross-validated mean squared error. As lambda decreases, the mean squared error decreases. Ridge includes all the variables in the model and the value of lambda selected is indicated by the vertical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37fa8e-59fd-415c-956b-f74bd403a621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3157cd1-c89f-4efc-9106-4941d98cdad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab529a-2b95-4961-baed-2964d0c2ee5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de056726-3fce-4dd4-a7c1-bbb6d4b056c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e29ac8-1795-48ed-a2d3-dd8cfc0b041a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac872e-8886-4ad9-9978-1a98276dcaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffae5a2-4579-4451-9dbc-e340536a7198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15a0a4-4f3c-4c45-8e36-891a0a0f8eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ece14-c4a2-4155-9d06-24186b6a13b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
