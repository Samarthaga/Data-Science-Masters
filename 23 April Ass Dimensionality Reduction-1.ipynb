{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3028231-926b-472e-af9e-e3f3ef5839bc",
   "metadata": {},
   "source": [
    "# Assignment 23 April Dimensionality Reduction-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c8a47-81f7-495a-8070-7cd2c593ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1: The curse of dimensionality basically refers to the difficulties a machine learning algorithm faces when working with data in the higher dimensions, that did not exist in the lower dimensions. This happens because when you add dimensions (features), the minimum data requirements also increase rapidly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edaad25-fdba-4da7-ba7c-2f885478ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2: As the dimensionality increases, the number of data points required for good performance of any machine learning algorithm increases exponentially. The reason is that, we would need more number of data points for any given combination of features, for any machine learning model to be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2337b-09a1-409f-b10f-e6e5db05e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3: Effect of Curse of Dimensionality on Distance Functions:\n",
    "# Therefore, any machine learning algorithms which are based on the distance measure including KNN(k-Nearest Neighbor) tend to fail when the number of dimensions in the data is very high\n",
    "# it can be reduced by One of the ways to reduce the impact of high dimensions is to use a different measure of distance in a space vector. One could explore the use of cosine similarity to replace Euclidean distance . Cosine similarity can have a lesser impact on data with higher dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ca5a7-858d-49cc-b8fe-f14785042d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 4 : Feature selection is simply selecting and excluding given features without changing them. Dimensionality reduction transforms features into a lower dimension\n",
    "# it is more of like changing the imp features and transforming into a new feature which is based on the relationship b/w the features for output to be predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e20b8-56e3-439c-8423-4ebb77c0adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 5: We lost some data during the dimensionality reduction process, which can impact how well future training algorithms work. It may need a lot of processing power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855f851-9733-489b-bb34-a2dc65932b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 6: KNN is very susceptible to overfitting due to the curse of dimensionality. Curse of dimensionality also describes the phenomenon where the feature space becomes increasingly sparse for an increasing number of dimensions of a fixed-size training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5caa4-0fb8-4282-877a-b525a16f5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 7: Eigenvalue Decomposition and Singular Value Decomposition(SVD) from linear algebra are the two main procedures used in PCA to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709d8ce-41ed-4505-9d30-dd7f7508c139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41273f76-16ec-41e4-8ed2-b8b16c7b7e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e04fda-5c8e-4ea2-a835-4385633ba317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f7c9e-bc66-43b1-afe5-b863124d6c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37dbdc-5cfa-49b3-86e4-590e014cb3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4e7d6-e0e0-4ada-8b70-10f89a498992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3409329-488a-4415-bf1a-617b6b50513a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
