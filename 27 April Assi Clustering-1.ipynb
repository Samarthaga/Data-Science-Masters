{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761b2a8e-d39f-44ef-b448-e7113661cce7",
   "metadata": {},
   "source": [
    "# Assignment 27 April Clustering-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffae4f6e-3770-4329-9eec-0f55e072446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1: K Means Algorithm,Hiararcial Clustering,DB scan Clustering,Silhoutte Scoring \n",
    "## for K means the value of k is determined to know the no of clusters and centroid is found ,\n",
    "## for Hiarchical similarity clusters are made without centroid \n",
    "## for DBSCAN handles the outliers in an amazing way \n",
    "## Silhoutte score is done in 3 steps , 1st calculate the avg. distance,then 2nd step finding the mean similarity b/w the 2 clusters and then 3rd step calculating the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13ba9dd-6af7-42ba-b855-58682a08001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2: K-Means clustering is an unsupervised learning algorithm. There is no labeled data for this clustering, unlike in supervised learning. K-Means performs the division of objects into clusters that share similarities and are dissimilar to the objects belonging to another cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fac7adbd-e5e2-4a41-9804-14c01c78df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3: Advantages of k-means: 1. Relatively simple to implement, 2. Scales to large data sets, 3.Guarantees convergence, 4.Can warm-start the positions of centroids\n",
    "# 5. Easily adapts to new examples, 6.Generalizes to clusters of different shapes and sizes, such as elliptical clusters\n",
    "# Limitations : k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98e8b3d-8045-4606-b6fa-b44bd57206d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 4: The silhouette coefficient may provide a more objective means to determine the optimal number of clusters. This is done by simply calculating the silhouette coefficient over a range of k, & identifying the peak as optimum K\n",
    "# Methods : The k-Means Elbow method is used to find the optimal value of the K in the K-Means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed14a01-defe-4a8e-b451-e0ad35d5ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 5: for the credit card in a bank Kmmeans Clustering can be used to find the similarity in the customer by their score of credit and salaryu and expenditure pattern \n",
    "# it helps the team to understand the optimal range of money limit that can be provdied for that cluster of group and can maintain a good and reliable data for future prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc12953-52f1-49d5-8ed9-45bd86802a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 6: The output of kmeans is a list with several bits of information. The most important being: cluster : A vector of integers (from 1:k) indicating the cluster to which each point is allocated. centers : A matrix of cluster centers\n",
    "# the insights are we can identify the groups and the centroids for the datasets and can also divide further as per the requirements\n",
    "# also we can differciate the clusters via looking at it and categorization can be done easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb300b-86d5-4526-b1d2-f25bfe438b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 7: k-means has trouble clustering data where clusters are of varying sizes and density. To cluster such data, you need to generalize k-means as described in the Advantages section. Clustering outliers. Centroids can be dragged by outliers, or outliers might get their own cluster instead of being ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbf6d8-314c-4269-b298-96ec344f40ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c01d4-62d2-4aff-ac03-09e4454e1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626de3a2-754b-47b9-bdeb-682fab414ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cefaba-d6d8-4373-a686-7979a2adf878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ade34b-a66e-40a4-94d9-f0859b3c283b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af3d43-9cee-4309-b67b-440c685964e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fded2-0100-4afa-bce4-1b516c0c91f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
