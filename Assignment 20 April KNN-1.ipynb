{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4a208-cadb-4a42-a51a-e9c3875f7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 1: The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point. While it can be used for either regression or classification problems, it is typically used as a classification algorithm, working off the assumption that similar points can be found near one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba263339-2da5-471a-85ef-f860f47bbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2: The choice of k will largely depend on the input data as data with more outliers or noise will likely perform better with higher values of k. Overall, it is recommended to have an odd number for k to avoid ties in classification, and cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7e34a-86d3-4653-a801-7f09494f13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3: The key differences are: KNN regression tries to predict the value of the output variable by using a local average. KNN classification attempts to predict the class to which the output variable belong by computing the local probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb2a7d-7481-475c-932a-ab8de2954545",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 4: To measure the performace of the KNN we divide the data in train and test data and then perform KNN classification for binary multiclass and\n",
    "# KNN regressor for continuous output where after train test and fit we perform the predict on our test data and take accuracy_score(),confusion_matrix(),classification_report() for classification and mean_sqrt_error,mean_absolute error for regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a127dda-1aff-406e-9667-4e95112db2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 5: The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size of your data set must also grow exponentially in order to keep the same density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf2bb9-8076-43b9-a8d5-4dd5fdc4e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 6: The idea in kNN methods is to identify 'k' samples in the dataset that are similar or close in the space. Then we use these 'k' samples to estimate the value of the missing data points. Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184637b-f46f-4442-95a4-a58ea7b9dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 7: KNN classifier is better for classification problems where the variable is binary or categorical , however the KNN regressor is better where the outut is an continuous value and numerical where the avg is computed for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324ab4e-15f9-4472-9a93-1c245fa43681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 8: KNN classifier It has advantages - nonparametric architecture, simple and powerful, requires no traning time, but it also has disadvantage - memory intensive, classification and estimation are slow\n",
    "# KNN can therefore be a relatively slow method compared to other regressions that may take longer to fit but then make their predictions with relatively straightforward computations. One other issue with a KNN model is that it lacks interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da81c81-2948-4159-bbaf-0b6c6d2ed6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 9: Euclidean distance is the shortest path between source and destination which is a straight line but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17dbd27-ee55-41ce-95ef-e877880fc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 10: Yes, feature scaling is required to get the better performance of the KNN algorithm. For Example, Imagine a dataset having n number of instances and N number of features. There is one feature having values ranging between 0 and 1. Meanwhile, there is also a feature that varies from -999 to 999\n",
    "# with the help of feature scaling the data representation and its range gets better via preprocessing import StandardScaler from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b2696-04f8-45fa-96ce-b4f2cdf65bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205aa99-a643-407e-8aa1-1c1cce5a755a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ba2a0-6737-4f0d-8733-82ca0fc439fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49aefbe-9f56-4c26-972f-73237ab98edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9baf4-7e32-4884-87fd-08017bdf6792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234cb6a6-c9db-4777-94b6-516daea9763a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e03bd-a89f-4078-a256-fc120258e851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e3360-06f1-4dc8-a720-8262ec79d54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358de85-49d2-4b9b-8f4c-6d71f100d673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc685d-2138-422c-8496-bae1d34e5e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c1bad-f023-4dfd-aa45-8de4dc300bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a73cea-51c0-4b1d-bb22-ad379d222bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756c994-2026-4107-aa0b-644cf134aa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb9632-40e4-48b6-8a56-5913ef48cc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3f1eb-4069-4b40-9c23-0e32339b5d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
