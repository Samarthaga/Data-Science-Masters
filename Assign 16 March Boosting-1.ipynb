{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5281ac-5401-4d6b-acb0-989a6920cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1:Boosting is a method used in machine learning to reduce errors in predictive data analysis. Data scientists train machine learning software, called machine learning models, on labeled data to make guesses about unlabeled data. A single machine learning model might make prediction errors depending on the accuracy of the training dataset. For example, if a cat-identifying model has been trained only on images of white cats, it may occasionally misidentify a black cat. Boosting tries to overcome this issue by training multiple models sequentially to improve the accuracy of the overall system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7f916-84f4-47fb-b9d2-18b315474077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2: Boosting is a resilient method that curbs over-fitting easily. One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d19f22-e7b8-41e7-857c-358e6d95303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3 : Step 1 : The boosting algorithm assigns equal weight to each data sample. It feeds the data to the first machine model, called the base algorithm. The base algorithm makes predictions for each data sample\n",
    "# Step 2 :The boosting algorithm assesses model predictions and increases the weight of samples with a more significant error. It also assigns a weight based on model performance. A model that outputs excellent predictions will have a high amount of influence over the final decision\n",
    "# Step 3 :The algorithm passes the weighted data to the next decision tree.\n",
    "# Step 4 : The algorithm repeats steps 2 and 3 until instances of training errors are below a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74fb0e-18c1-480e-86a5-76ab376f2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 4: Adaptive boosting\n",
    "# Gradient boosting\n",
    "# Extreme gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e184f-f10e-4346-a489-c05263beed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 5: n.trees – Number of trees (the number of gradient boosting iteration) i.e. N. Increasing N reduces the error on training set, but setting it too high may lead to over-fitting\n",
    "# interaction.depth (Maximum nodes per tree) - number of splits it has to perform on a tree (starting from a single node).\n",
    "# Shrinkage (Learning Rate) – It is considered as a learning rate.Shrinkage is commonly used in ridge regression where it reduces regression coefficients to zero and, thus, reduces the impact of potentially unstable regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1547f-e4f4-40db-86da-8302f046b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 6: Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda5e0b-925d-453d-b547-85b6fd9fe09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 7: AdaBoost algorithm, short for Adaptive Boosting, is a Boosting technique used as an Ensemble Method in Machine Learning. It is called Adaptive Boosting as the weights are re-assigned to each instance, with higher weights assigned to incorrectly classified instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d2eb0-be7b-4ad3-8fc6-62a932d7018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 8:The error function that AdaBoost uses is an exponential loss function. First we find the products between the true values of training samples and the overall prediction for each sample. Then we take the sum of all the exponentials of these products in order to compute the error at iteration m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab23d6f-42e6-456e-8b7c-b8002979b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 9:This is done by making misclassified cases to be updated with increased weights after an iteration. Increased weights would make our learning algorithm pay higher attention to these observations in the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5b7ce-c2f8-4ba1-9753-38b5d5e96c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 10:if i increace the no of estimators the time complexicity increases and also cost fn inc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9e386-d53c-4d39-862a-3e9372c8cd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640b0c8b-e1a6-42da-b981-687ca5d22608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94f31c-fdbc-4400-97b3-8fda6caf4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eaf20d-d755-43de-8bed-e1791a76b9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef552502-42f8-4f08-932e-403082733f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71d9cc-ec45-4068-b1d9-2d05d32dda9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c7f52-1a1b-4b7b-bebf-645d6cd45e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec38d8-5503-43d1-9fd7-b62c423cf2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
