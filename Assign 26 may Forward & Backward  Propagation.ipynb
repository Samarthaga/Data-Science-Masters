{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacf1be-b0fc-4415-af2e-a8797e5b4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1: Forward propagation is where input data is fed through a network, in a forward direction, to generate an output. The data is accepted by hidden layers and processed, as per the activation function, and moves to the successive layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08886f31-508d-4704-9590-d17d8eec74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2: During forward propagation at each node of hidden and output layer preactivation and activation takes place. For example at the first node of the hidden layer, a1(preactivation) is calculated first and then h1(activation) is calculated. a1 is a weighted sum of inputs. Here, the weights are randomly generated.\n",
    "# Forward propagation is where input data is fed through a network, in a forward direction, to generate an output. The data is accepted by hidden layers and processed, as per the activation function, and moves to the successive layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73e9570-2538-45f6-95b4-3a5dba18f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 3 : During forward propagation, pre-activation and activation take place at each hidden and output layer node of a neural network. The pre-activation function is the calculation of the weighted sum. The activation function is applied, based on the weighted sum, to make the neural network flow non-linearly using bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beac126-5f98-45d7-8d76-90ab59b88bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 4: Weights set the standards for the neuron's signal strength. This value will determine the influence input data has on the output product. Biases give extra characteristics with a value of 1 that the neural network did not previously have. The neural network needs that extra information to efficiently propagate forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e94ae1-a4aa-489b-a563-fc5ef8bd1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 5: The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. That is, softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de5523-4eca-427a-b9e5-04c7d9efb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 6: Backpropagation algorithms are used extensively to train feedforward neural networks in areas such as deep learning. They efficiently compute the gradient of the loss function with respect to the network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdfa8b-fef5-4fc7-8057-8d8f3d05a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 7: The backpropagation algorithm performs learning on a multilayer feed-forward neural network. It iteratively learns a set of weights for prediction of the class label of tuples. A multilayer feed-forward neural network consists of an input layer, one or more hidden layers, and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3c1d7-1113-4888-8f40-cf5005ed708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 8 : The chain rule can be generalised to multivariate functions, and represented by a tree diagram. The chain rule is applied extensively by the backpropagation algorithm in order to calculate the error gradient of the loss function with respect to each weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7b131-fe90-4772-8f70-24545bc55387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 9: The actual performance of backpropagation on a specific problem is dependent on the input data.\n",
    "# Back propagation algorithm in data mining can be quite sensitive to noisy data.\n",
    "# You need to use the matrix-based approach for backpropagation instead of mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4aa48-6457-4ae8-a7c2-06cc0b8fc8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3432753-b4b2-472f-86fd-adf5c2bb4cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba4f12-0963-41dd-ad87-803dfc3ca458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3dae8-7a49-4cab-a370-cb2b22930f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02fe9a6-ee53-45bd-b46e-e6332652123d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72455b3b-d7eb-4eef-aaa5-ce142c61c1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9df75-bd23-445d-b3c0-8f337f208245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6b7f7-f15b-41d1-bc9f-eb7f81fd31f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8358f18-7a6e-4bd3-b485-ad504617ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d1612-d7b3-4531-84fc-51bb25bc7b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
